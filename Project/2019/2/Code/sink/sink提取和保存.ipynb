{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    file  \\\n",
      "0      CWE_79__POST__func_FILTER-CLEANING-email_filte...   \n",
      "1      CWE_79__system__func_urlencode__Use_untrusted_...   \n",
      "2      CWE_79__object-directGet__no_sanitizing__Unsaf...   \n",
      "3      CWE_79__proc_open__func_FILTER-VALIDATION-numb...   \n",
      "4      CWE_79__object-Array__ternary_white_list__Use_...   \n",
      "...                                                  ...   \n",
      "10075  CWE_79__object-indexArray__func_urlencode__Use...   \n",
      "10076  CWE_79__backticks__CAST-cast_float_sort_of__Us...   \n",
      "10077  CWE_79__POST__CAST-cast_float__Use_untrusted_d...   \n",
      "10078  CWE_79__object-classicGet__CAST-func_settype_i...   \n",
      "10079  CWE_79__popen__func_FILTER-CLEANING-full_speci...   \n",
      "\n",
      "                                              sourcecode  \\\n",
      "0      <!-- \\nUnsafe sample\\ninput : get the field Us...   \n",
      "1      <!-- \\nUnsafe sample\\ninput : execute a ls com...   \n",
      "2      <!-- \\nUnsafe sample\\ninput : get the field us...   \n",
      "3      <!-- \\nUnsafe sample\\ninput : use proc_open to...   \n",
      "4      <!-- \\nUnsafe sample\\ninput : get the field us...   \n",
      "...                                                  ...   \n",
      "10075  <!-- \\nSafe sample\\ninput : get the field user...   \n",
      "10076  <!-- \\nSafe sample\\ninput : backticks interpre...   \n",
      "10077  <!-- \\nSafe sample\\ninput : get the field User...   \n",
      "10078  <!-- \\nSafe sample\\ninput : get the field user...   \n",
      "10079  <!-- \\nSafe sample\\ninput : Uses popen to read...   \n",
      "\n",
      "                                                     vld  \\\n",
      "0      <!-- \\nUnsafe sample\\ninput : get the field Us...   \n",
      "1      <!-- \\nUnsafe sample\\ninput : execute a ls com...   \n",
      "2      <!-- \\nUnsafe sample\\ninput : get the field us...   \n",
      "3      <!-- \\nUnsafe sample\\ninput : use proc_open to...   \n",
      "4      <!-- \\nUnsafe sample\\ninput : get the field us...   \n",
      "...                                                  ...   \n",
      "10075  <!-- \\nSafe sample\\ninput : get the field user...   \n",
      "10076  <!-- \\nSafe sample\\ninput : backticks interpre...   \n",
      "10077  <!-- \\nSafe sample\\ninput : get the field User...   \n",
      "10078  <!-- \\nSafe sample\\ninput : get the field user...   \n",
      "10079  <!-- \\nSafe sample\\ninput : Uses popen to read...   \n",
      "\n",
      "                                                  opcode  label  \n",
      "0      STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      1  \n",
      "1      SANITIZE STIVALET IN EVENT AUTHORS LIABLE ANY ...      1  \n",
      "2      STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      1  \n",
      "3      STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      1  \n",
      "4      STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      1  \n",
      "...                                                  ...    ...  \n",
      "10075  SANITIZE STIVALET IN EVENT AUTHORS LIABLE ANY ...      0  \n",
      "10076  STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      0  \n",
      "10077  STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      0  \n",
      "10078  STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      0  \n",
      "10079  STIVALET IN EVENT AUTHORS LIABLE ANY FOR OR DA...      0  \n",
      "\n",
      "[10080 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "data_pd = pd.read_csv('./../')\n",
    "print(data_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080,)\n"
     ]
    }
   ],
   "source": [
    "code_list = data_pd['sourcecode']\n",
    "code_list = np.array(code_list)\n",
    "print(code_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080,)\n",
      "['$tainted ' '\"body { color :\\\\\"\". $tainted .\"\\\\\" ; }\" ' '$tainted ' ...\n",
      " '\"<div onmouseover=\\\\\"x=\\\\\"\". $tainted .\"\\\\\"\\\\>\"'\n",
      " '\"<\".  $tainted .\" href= \\\\\"/bob\\\\\" />\" '\n",
      " '\"<div id=\\\\\"\". $tainted .\"\\\\\">content</div>\" ']\n"
     ]
    }
   ],
   "source": [
    "ptrn = r'echo\\s(.+)\\s*;'\n",
    "# ptrn2 = r'echo\\s\\\"(.+)\\\"\\s*'\n",
    "\n",
    "sink_list = []\n",
    "for code in code_list:\n",
    "    sink = re.findall(pattern=ptrn, string=code)\n",
    "    if sink == []:\n",
    "        print(code)\n",
    "    if type(sink) == 'str':\n",
    "        sink_list.append(sink)\n",
    "    else:\n",
    "        for element in sink:\n",
    "            sink_list.append(element)\n",
    "#     print(type(sink))\n",
    "sink_list = np.array(sink_list)\n",
    "print(sink_list.shape)\n",
    "print(sink_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sink in sink_list:\n",
    "    if sink[0] == '\\\"' and sink[-1] == '\\\"':\n",
    "        sink = sink[1:-1]\n",
    "#         print(sink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/devin/Desktop/sink.txt', mode='w', encoding='utf8') as f:\n",
    "    for sink in sink_list:\n",
    "        f.write(sink + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面是模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080,)\n",
      "(10080,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(data_pd['label'].tolist())\n",
    "\n",
    "print(sink_list.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080, 13)\n",
      "(7056, 13)\n",
      "[[-0.40089553 -0.22465298 -0.40706628 -0.32337451 -0.22845583 -0.40706628\n",
      "  -0.32337451 -0.22465298 -0.22465298 -0.40706628 -0.22465298 -0.22255664\n",
      "  -0.22500083]\n",
      " [ 2.49441546 -0.22465298 -0.40706628 -0.32337451 -0.22845583 -0.40706628\n",
      "  -0.32337451 -0.22465298 -0.22465298 -0.40706628 -0.22465298 -0.22255664\n",
      "  -0.22500083]\n",
      " [ 2.49441546 -0.22465298 -0.40706628 -0.32337451 -0.22845583 -0.40706628\n",
      "  -0.32337451 -0.22465298 -0.22465298 -0.40706628 -0.22465298 -0.22255664\n",
      "  -0.22500083]\n",
      " [-0.40089553  4.45130984 -0.40706628 -0.32337451 -0.22845583 -0.40706628\n",
      "  -0.32337451  4.45130984  4.45130984 -0.40706628  4.45130984 -0.22255664\n",
      "  -0.22500083]\n",
      " [-0.40089553  4.45130984 -0.40706628 -0.32337451 -0.22845583 -0.40706628\n",
      "  -0.32337451  4.45130984  4.45130984 -0.40706628  4.45130984 -0.22255664\n",
      "  -0.22500083]]\n",
      "[0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "CV = CountVectorizer(ngram_range=(3,3), decode_error='ignore',\n",
    "                    token_pattern=r'\\b\\w+\\b', min_df=1, max_df=1.0)\n",
    "X = CV.fit_transform(sink_list).toarray()\n",
    "\n",
    "Tfid = TfidfTransformer(smooth_idf=False)\n",
    "X_tfid = np.array(Tfid.fit_transform(X).toarray())\n",
    "print(X_tfid.shape)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfid, y, random_state=None, test_size = 0.3, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "print(X_train_std.shape)\n",
    "print(X_test_std[:5])\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training.\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Good sanitize       0.70      0.81      0.75      1718\n",
      " Bad sanitize       0.68      0.53      0.60      1306\n",
      "\n",
      "     accuracy                           0.69      3024\n",
      "    macro avg       0.69      0.67      0.67      3024\n",
      " weighted avg       0.69      0.69      0.69      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "svc = svm.SVC(kernel='linear', C=1.0, gamma='auto', probability=True, random_state=None).fit(X_train_std, y_train)  # 线性核\n",
    "# rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=1.0).fit(X_train, y_train)  # 径向基核\n",
    "# poly_svc = svm.SVC(kernel='poly', degree=3, C=1.0, gamma='auto').fit(X_train, y_train)  # 多项式核\n",
    "print('Finished training.\\n');\n",
    "\n",
    "predict_target = svc.predict(X_test_std)\n",
    "print(metrics.classification_report(y_test, predict_target, \n",
    "                                    target_names=['Good sanitize', 'Bad sanitize']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
