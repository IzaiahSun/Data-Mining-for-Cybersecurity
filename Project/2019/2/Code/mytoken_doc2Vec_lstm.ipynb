{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from my_tokenize3 import my_token_get_all, feature_vector_helper\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取目录下所有php文件的路径，返回一个路径的列表\n",
    "def load_all_php_path(dir):\n",
    "    filelist = []\n",
    "    \n",
    "#     root为dir目录地址\n",
    "#     dirs是一个该文件夹下所有目录名的list\n",
    "#     filelist是文件名的list\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.php'):\n",
    "                fullpath = os.path.join(root, file)\n",
    "#                 print('Loading %s' % fullpath)\n",
    "                filelist.append(fullpath)\n",
    "    return filelist\n",
    "\n",
    "# 读取每一份代码，返回代码内容\n",
    "def load_one_file(filename):\n",
    "    context = ''\n",
    "    with open(filename, 'r', encoding='utf-8', errors='ignore') as codes:\n",
    "        for line in codes:\n",
    "            line = line.strip('\\r')\n",
    "            context += line\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4352\n",
      "5728\n",
      "10080\n"
     ]
    }
   ],
   "source": [
    "black_file_paths = load_all_php_path('./dataset-clean/bad/')\n",
    "white_file_paths = load_all_php_path('./dataset-clean/good/')\n",
    "all_paths = black_file_paths + white_file_paths\n",
    "print(len(black_file_paths))\n",
    "print(len(white_file_paths))\n",
    "print(len(all_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080,)\n",
      "(10080,)\n",
      "['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML', 'T_TAG_BODY', 'T_TAG_PHP', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_ADDSLASHES', 'T_SINK_TYPE_15', 'T_TAG_PHP', 'T_TAG_DIV', 'T_TAG_BODY', 'T_TAG_HTML']\n"
     ]
    }
   ],
   "source": [
    "token_list = []\n",
    "label_list = []\n",
    "\n",
    "for file in black_file_paths:\n",
    "    token = feature_vector_helper(my_token_get_all(file))\n",
    "    if len(token) != 0:\n",
    "        token_list.append(token)\n",
    "        label_list.append('1')\n",
    "    else:\n",
    "        print('get code token error')\n",
    "        \n",
    "for file in white_file_paths:\n",
    "    token = feature_vector_helper(my_token_get_all(file))\n",
    "    if len(token) != 0:\n",
    "        token_list.append(token)\n",
    "        label_list.append('0')\n",
    "    else:\n",
    "        print('get code token error')\n",
    "        \n",
    "token_list = np.array(token_list)\n",
    "label_list = np.array(label_list)\n",
    "print(token_list.shape)\n",
    "print(label_list.shape)\n",
    "print(token_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_SINGLE_QUOTE_ATTR_VAL', 'T_TAG_PHP_END', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_NO_QUOTE_ATTR_VAL', 'T_TAG_PHP_END', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_START', 'T_TAG_STYLE_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_BODY_SECTION', 'T_TAG_PHP_END', 'T_TAG_STYLE_END', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_START', 'T_TAG_STYLE_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_BODY_SECTION', 'T_TAG_PHP_END', 'T_TAG_STYLE_END', 'T_TAG_SCRIPT_END', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_START', 'T_TAG_STYLE_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_BODY_SECTION', 'T_TAG_PHP_END', 'T_TAG_STYLE_END', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_BODY_SECTION', 'T_TAG_PHP_END', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_SINGLE_QUOTE_ATTR_VAL', 'T_TAG_PHP_END', 'T_TAG_DIV_END', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_START', 'T_TAG_SCRIPT_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_SINGLE_QUOTE_JS_BLOCK', 'T_TAG_PHP_END', 'T_TAG_SCRIPT_END', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_START', 'T_TAG_SCRIPT_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_SINGLE_QUOTE_ATTR_VAL', 'T_TAG_PHP_END', 'T_TAG_SCRIPT_END', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])\n",
      " list(['T_TAG_DOCTYPE_HTML', 'T_TAG_HTML_START', 'T_TAG_HEAD_START', 'T_TAG_SCRIPT_START', 'T_TAG_PHP_START', 'T_VAR_ASSIGN_BY_ORDINARY_FUNCTION', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SOURCE_$_GET', 'T_VAR_ASSIGN_COMMON', 'T_VAR_ASSIGN_COMMON', 'T_VAR_SANITIZE_BY_FILTER_VAR_FILTER_SANITIZE_EMAIL', 'T_LOGIC_IF', 'T_VAR_ASSIGN_COMMON', 'T_LOGIC_ELSE', 'T_VAR_ASSIGN_COMMON', 'T_SINK_SINGLE_QUOTE_JS_BLOCK', 'T_TAG_PHP_END', 'T_TAG_SCRIPT_END', 'T_TAG_HEAD_END', 'T_TAG_BODY_START', 'T_TAG_BODY_END', 'T_TAG_HTML_END'])]\n"
     ]
    }
   ],
   "source": [
    "print(token_list[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10080,)\n",
      "(10080,)\n"
     ]
    }
   ],
   "source": [
    "from nltk import wordpunct_tokenize\n",
    "\n",
    "raw_token_list = []\n",
    "label_list = []\n",
    "\n",
    "for file in black_file_paths:\n",
    "    with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = wordpunct_tokenize(f.read())\n",
    "        raw_token_list.append(content)\n",
    "        f.close()\n",
    "        label_list.append('1')\n",
    "        \n",
    "for file in white_file_paths:\n",
    "    with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        content = wordpunct_tokenize(f.read())\n",
    "        raw_token_list.append(content)\n",
    "        f.close()\n",
    "        label_list.append('0')\n",
    "        \n",
    "raw_token_list = np.array(raw_token_list)\n",
    "label_list = np.array(label_list)\n",
    "print(raw_token_list.shape)\n",
    "print(label_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2Vec分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080\n"
     ]
    }
   ],
   "source": [
    "tgd_document = [TaggedDocument(doc, [i]) for doc, i in zip(token_list, all_paths)]\n",
    "print(len(tgd_document))\n",
    "doc_model = Doc2Vec(min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n"
     ]
    }
   ],
   "source": [
    "doc_model.build_vocab(tgd_document)\n",
    "doc_model.train(tgd_document, total_examples=doc_model.corpus_count, epochs=10)\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157956\n"
     ]
    }
   ],
   "source": [
    "print(doc_model.corpus_total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model.save('doc2Vec_raw_token.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model = Doc2Vec.load('doc2Vec_token.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10080\n",
      "10080\n",
      "(100,)\n",
      "(10080, 100)\n"
     ]
    }
   ],
   "source": [
    "print(len(doc_model.docvecs))\n",
    "print(doc_model.corpus_count)\n",
    "print(doc_model.docvecs[0].shape)\n",
    "doc_vec_list = doc_model.docvecs.vectors_docs\n",
    "print(doc_vec_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "token_str_list = []\n",
    "for token in token_list:\n",
    "    token = ' '.join(token)\n",
    "    token_str_list.append(token)\n",
    "    \n",
    "doc2Vec_dict = {\n",
    "    'file_path': all_paths,\n",
    "    'token': token_str_list,\n",
    "#     'vector': doc_vec_list,\n",
    "    'label': label_list\n",
    "}\n",
    "doc2Vec_df = pd.DataFrame(doc2Vec_dict)\n",
    "doc2Vec_df.to_csv('testtttttt.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_VAR_SOURCE_$_GET', 'T_VAR_SANITIZE_BY_ADDSLASHES', 'T_SINK_ATTR_NAME']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for token in token_list:\n",
    "#     print(token)\n",
    "    corpus.append(token)\n",
    "corpus = np.array(corpus)\n",
    "print(corpus[0])\n",
    "w2v_model = Word2Vec(corpus, size=100, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 100)\n",
      "(29,)\n"
     ]
    }
   ],
   "source": [
    "wv = np.array(w2v_model.wv.vectors)\n",
    "words = np.array(w2v_model.wv.index2word)\n",
    "print(wv.shape)\n",
    "print(words.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_vec_list, label_list, \n",
    "                                                    random_state=2019, test_size = 0.2, stratify=label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train).astype('float32').reshape(-1, 100, 1)\n",
    "X_test_std = scaler.fit_transform(X_test).astype('float32').reshape(-1, 100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.98713356]\n",
      " [ 0.23830652]\n",
      " [ 1.3215753 ]\n",
      " [-0.39758846]\n",
      " [ 1.1049883 ]\n",
      " [-0.1060916 ]\n",
      " [-1.5417783 ]\n",
      " [-0.39726794]\n",
      " [-0.7075006 ]\n",
      " [-1.0773247 ]\n",
      " [-0.0627264 ]\n",
      " [ 0.33799082]\n",
      " [ 0.9908572 ]\n",
      " [-0.36377394]\n",
      " [ 0.13662373]\n",
      " [ 0.56917447]\n",
      " [-1.5725927 ]\n",
      " [ 0.6334588 ]\n",
      " [ 1.779405  ]\n",
      " [-0.9299604 ]\n",
      " [ 0.42101318]\n",
      " [-0.030726  ]\n",
      " [ 0.06546658]\n",
      " [ 0.28070685]\n",
      " [-0.27652687]\n",
      " [ 0.45746678]\n",
      " [-0.2790404 ]\n",
      " [ 1.3612814 ]\n",
      " [-0.53467274]\n",
      " [-1.2548751 ]\n",
      " [-0.51373434]\n",
      " [ 0.472557  ]\n",
      " [ 1.0438993 ]\n",
      " [ 0.7619127 ]\n",
      " [ 0.92010343]\n",
      " [ 2.0587711 ]\n",
      " [ 2.1426845 ]\n",
      " [-1.3844591 ]\n",
      " [-0.6839878 ]\n",
      " [-0.45605454]\n",
      " [-0.10832098]\n",
      " [ 0.5458253 ]\n",
      " [-0.07392456]\n",
      " [-1.9689234 ]\n",
      " [ 0.08535058]\n",
      " [ 0.6397421 ]\n",
      " [ 0.45846584]\n",
      " [ 0.3553909 ]\n",
      " [ 0.01542908]\n",
      " [-0.7291864 ]\n",
      " [-1.8248147 ]\n",
      " [-0.65871817]\n",
      " [-1.297065  ]\n",
      " [-0.12290539]\n",
      " [ 0.48453587]\n",
      " [-0.6841087 ]\n",
      " [ 0.703199  ]\n",
      " [ 0.36211398]\n",
      " [ 0.47200456]\n",
      " [-0.05922444]\n",
      " [ 1.1127754 ]\n",
      " [ 0.8170991 ]\n",
      " [-1.0728669 ]\n",
      " [-1.8385667 ]\n",
      " [-0.32584313]\n",
      " [ 0.96379113]\n",
      " [-1.9456263 ]\n",
      " [-0.66925836]\n",
      " [ 0.3110032 ]\n",
      " [-0.54106015]\n",
      " [ 0.5444196 ]\n",
      " [-1.5372415 ]\n",
      " [-1.8422266 ]\n",
      " [-1.3397106 ]\n",
      " [ 0.31076428]\n",
      " [-0.67867374]\n",
      " [-0.4051641 ]\n",
      " [-1.1482962 ]\n",
      " [-0.60707825]\n",
      " [ 0.4829359 ]\n",
      " [ 0.08114437]\n",
      " [-0.6835992 ]\n",
      " [-1.3647746 ]\n",
      " [ 1.188461  ]\n",
      " [ 2.3363185 ]\n",
      " [-1.724749  ]\n",
      " [ 0.93100697]\n",
      " [ 0.52296644]\n",
      " [-0.22935319]\n",
      " [ 1.1498076 ]\n",
      " [-0.05927193]\n",
      " [-0.20745395]\n",
      " [-1.5000675 ]\n",
      " [-0.11721379]\n",
      " [-0.8430449 ]\n",
      " [ 0.02914292]\n",
      " [ 0.9326973 ]\n",
      " [-1.7531393 ]\n",
      " [-0.6368508 ]\n",
      " [ 0.10816482]]\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "print(X_train_std[index])\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8064, 100, 1)\n",
      "(8064, 2)\n",
      "(2016, 100, 1)\n",
      "(2016,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_std.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test_std.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Embedding, Dropout, Bidirectional, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(X_train.shape[0], 100, input_length=100))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.25, recurrent_dropout=0.25)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('rawtoken_doc2Vec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 6451 samples, validate on 1613 samples\n",
      "Epoch 1/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6710 - acc: 0.5964 - val_loss: 0.6677 - val_acc: 0.5927\n",
      "Epoch 2/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6620 - acc: 0.6056 - val_loss: 0.6601 - val_acc: 0.6045\n",
      "Epoch 3/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6607 - acc: 0.6166 - val_loss: 0.6598 - val_acc: 0.6107\n",
      "Epoch 4/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6624 - acc: 0.6027 - val_loss: 0.6603 - val_acc: 0.6206\n",
      "Epoch 5/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6589 - acc: 0.6148 - val_loss: 0.6662 - val_acc: 0.5896\n",
      "Epoch 6/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6553 - acc: 0.6208 - val_loss: 0.6755 - val_acc: 0.5834\n",
      "Epoch 7/400\n",
      "6451/6451 [==============================] - 48s 8ms/sample - loss: 0.6675 - acc: 0.6008 - val_loss: 0.6627 - val_acc: 0.6082\n",
      "Epoch 8/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6596 - acc: 0.6104 - val_loss: 0.6669 - val_acc: 0.5921\n",
      "Epoch 9/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6571 - acc: 0.6165 - val_loss: 0.6604 - val_acc: 0.6187\n",
      "Epoch 10/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6588 - acc: 0.6078 - val_loss: 0.6591 - val_acc: 0.6088\n",
      "Epoch 11/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6545 - acc: 0.6215 - val_loss: 0.6631 - val_acc: 0.6026\n",
      "Epoch 12/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6561 - acc: 0.6146 - val_loss: 0.6600 - val_acc: 0.6119\n",
      "Epoch 13/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6638 - acc: 0.6165 - val_loss: 0.6970 - val_acc: 0.5555\n",
      "Epoch 14/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6589 - acc: 0.6125 - val_loss: 0.6606 - val_acc: 0.6131\n",
      "Epoch 15/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6568 - acc: 0.6242 - val_loss: 0.6614 - val_acc: 0.6231\n",
      "Epoch 16/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6580 - acc: 0.6139 - val_loss: 0.6584 - val_acc: 0.6212\n",
      "Epoch 17/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6547 - acc: 0.6208 - val_loss: 0.6634 - val_acc: 0.6131\n",
      "Epoch 18/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6546 - acc: 0.6132 - val_loss: 0.6596 - val_acc: 0.6218\n",
      "Epoch 19/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6520 - acc: 0.6205 - val_loss: 0.6646 - val_acc: 0.6100\n",
      "Epoch 20/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6528 - acc: 0.6264 - val_loss: 0.6559 - val_acc: 0.6181\n",
      "Epoch 21/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6501 - acc: 0.6236 - val_loss: 0.6599 - val_acc: 0.6113\n",
      "Epoch 22/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6515 - acc: 0.6235 - val_loss: 0.6584 - val_acc: 0.6193\n",
      "Epoch 23/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6506 - acc: 0.6184 - val_loss: 0.6579 - val_acc: 0.6187\n",
      "Epoch 24/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6542 - acc: 0.6179 - val_loss: 0.6595 - val_acc: 0.6144\n",
      "Epoch 25/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6514 - acc: 0.6270 - val_loss: 0.6554 - val_acc: 0.6169\n",
      "Epoch 26/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6518 - acc: 0.6244 - val_loss: 0.6573 - val_acc: 0.6231\n",
      "Epoch 27/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6453 - acc: 0.6323 - val_loss: 0.6605 - val_acc: 0.6138\n",
      "Epoch 28/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6488 - acc: 0.6309 - val_loss: 0.6550 - val_acc: 0.6262\n",
      "Epoch 29/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6492 - acc: 0.6259 - val_loss: 0.6551 - val_acc: 0.6237\n",
      "Epoch 30/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6565 - acc: 0.6151 - val_loss: 0.6628 - val_acc: 0.6094\n",
      "Epoch 31/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6503 - acc: 0.6250 - val_loss: 0.6644 - val_acc: 0.6113\n",
      "Epoch 32/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6482 - acc: 0.6308 - val_loss: 0.6619 - val_acc: 0.6119\n",
      "Epoch 33/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6483 - acc: 0.6277 - val_loss: 0.6595 - val_acc: 0.6162\n",
      "Epoch 34/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6473 - acc: 0.6278 - val_loss: 0.6554 - val_acc: 0.6200\n",
      "Epoch 35/400\n",
      "6451/6451 [==============================] - 48s 8ms/sample - loss: 0.6454 - acc: 0.6353 - val_loss: 0.6562 - val_acc: 0.6249\n",
      "Epoch 36/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6466 - acc: 0.6326 - val_loss: 0.6564 - val_acc: 0.6138\n",
      "Epoch 37/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6432 - acc: 0.6325 - val_loss: 0.6558 - val_acc: 0.6175\n",
      "Epoch 38/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6484 - acc: 0.6303 - val_loss: 0.6591 - val_acc: 0.6113\n",
      "Epoch 39/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6504 - acc: 0.6292 - val_loss: 0.6606 - val_acc: 0.6187\n",
      "Epoch 40/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6490 - acc: 0.6255 - val_loss: 0.6639 - val_acc: 0.6082\n",
      "Epoch 41/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6480 - acc: 0.6256 - val_loss: 0.6623 - val_acc: 0.6131\n",
      "Epoch 42/400\n",
      "6451/6451 [==============================] - 51s 8ms/sample - loss: 0.6461 - acc: 0.6342 - val_loss: 0.6578 - val_acc: 0.6119\n",
      "Epoch 43/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6465 - acc: 0.6278 - val_loss: 0.6588 - val_acc: 0.6138\n",
      "Epoch 44/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6431 - acc: 0.6329 - val_loss: 0.6574 - val_acc: 0.6107\n",
      "Epoch 45/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6438 - acc: 0.6356 - val_loss: 0.6603 - val_acc: 0.6150\n",
      "Epoch 46/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6426 - acc: 0.6385 - val_loss: 0.6620 - val_acc: 0.6156\n",
      "Epoch 47/400\n",
      "6451/6451 [==============================] - 50s 8ms/sample - loss: 0.6412 - acc: 0.6393 - val_loss: 0.6587 - val_acc: 0.6181\n",
      "Epoch 48/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6450 - acc: 0.6357 - val_loss: 0.6563 - val_acc: 0.6119\n",
      "Epoch 49/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6403 - acc: 0.6349 - val_loss: 0.6574 - val_acc: 0.6138\n",
      "Epoch 50/400\n",
      "6451/6451 [==============================] - 50s 8ms/sample - loss: 0.6445 - acc: 0.6340 - val_loss: 0.6600 - val_acc: 0.6162\n",
      "Epoch 51/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6431 - acc: 0.6360 - val_loss: 0.6590 - val_acc: 0.6175\n",
      "Epoch 52/400\n",
      "6451/6451 [==============================] - 50s 8ms/sample - loss: 0.6413 - acc: 0.6354 - val_loss: 0.6623 - val_acc: 0.6224\n",
      "Epoch 53/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6403 - acc: 0.6334 - val_loss: 0.6565 - val_acc: 0.6162\n",
      "Epoch 54/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6368 - acc: 0.6436 - val_loss: 0.6567 - val_acc: 0.6243\n",
      "Epoch 55/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6368 - acc: 0.6441 - val_loss: 0.6551 - val_acc: 0.6150\n",
      "Epoch 56/400\n",
      "6451/6451 [==============================] - 50s 8ms/sample - loss: 0.6419 - acc: 0.6397 - val_loss: 0.6564 - val_acc: 0.6144\n",
      "Epoch 57/400\n",
      "6451/6451 [==============================] - 50s 8ms/sample - loss: 0.6370 - acc: 0.6447 - val_loss: 0.6563 - val_acc: 0.6193\n",
      "Epoch 58/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6377 - acc: 0.6428 - val_loss: 0.6590 - val_acc: 0.6125\n",
      "Epoch 59/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6382 - acc: 0.6363 - val_loss: 0.6526 - val_acc: 0.6162\n",
      "Epoch 60/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6385 - acc: 0.6415 - val_loss: 0.6551 - val_acc: 0.6249\n",
      "Epoch 61/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6330 - acc: 0.6483 - val_loss: 0.6562 - val_acc: 0.6212\n",
      "Epoch 62/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6348 - acc: 0.6435 - val_loss: 0.6563 - val_acc: 0.6255\n",
      "Epoch 63/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6339 - acc: 0.6498 - val_loss: 0.6509 - val_acc: 0.6311\n",
      "Epoch 64/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6336 - acc: 0.6501 - val_loss: 0.6555 - val_acc: 0.6293\n",
      "Epoch 65/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6325 - acc: 0.6514 - val_loss: 0.6518 - val_acc: 0.6280\n",
      "Epoch 66/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6339 - acc: 0.6475 - val_loss: 0.6528 - val_acc: 0.6367\n",
      "Epoch 67/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6309 - acc: 0.6489 - val_loss: 0.6553 - val_acc: 0.6274\n",
      "Epoch 68/400\n",
      "6451/6451 [==============================] - 51s 8ms/sample - loss: 0.6287 - acc: 0.6529 - val_loss: 0.6527 - val_acc: 0.6181\n",
      "Epoch 69/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6307 - acc: 0.6542 - val_loss: 0.6611 - val_acc: 0.6231\n",
      "Epoch 70/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6259 - acc: 0.6545 - val_loss: 0.6604 - val_acc: 0.6150\n",
      "Epoch 71/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6271 - acc: 0.6571 - val_loss: 0.6538 - val_acc: 0.6262\n",
      "Epoch 72/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6258 - acc: 0.6587 - val_loss: 0.6561 - val_acc: 0.6274\n",
      "Epoch 73/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6227 - acc: 0.6585 - val_loss: 0.6536 - val_acc: 0.6187\n",
      "Epoch 74/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6251 - acc: 0.6552 - val_loss: 0.6544 - val_acc: 0.6293\n",
      "Epoch 75/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6242 - acc: 0.6607 - val_loss: 0.6576 - val_acc: 0.6249\n",
      "Epoch 76/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6271 - acc: 0.6577 - val_loss: 0.6492 - val_acc: 0.6305\n",
      "Epoch 77/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6253 - acc: 0.6562 - val_loss: 0.6522 - val_acc: 0.6293\n",
      "Epoch 78/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6224 - acc: 0.6611 - val_loss: 0.6518 - val_acc: 0.6305\n",
      "Epoch 79/400\n",
      "6451/6451 [==============================] - 48s 8ms/sample - loss: 0.6195 - acc: 0.6573 - val_loss: 0.6625 - val_acc: 0.6317\n",
      "Epoch 80/400\n",
      "6451/6451 [==============================] - 47s 7ms/sample - loss: 0.6259 - acc: 0.6549 - val_loss: 0.6543 - val_acc: 0.6342\n",
      "Epoch 81/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6184 - acc: 0.6639 - val_loss: 0.6515 - val_acc: 0.6367\n",
      "Epoch 82/400\n",
      "6451/6451 [==============================] - 48s 8ms/sample - loss: 0.6163 - acc: 0.6658 - val_loss: 0.6557 - val_acc: 0.6367\n",
      "Epoch 83/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6207 - acc: 0.6613 - val_loss: 0.6528 - val_acc: 0.6224\n",
      "Epoch 84/400\n",
      "6451/6451 [==============================] - 49s 8ms/sample - loss: 0.6142 - acc: 0.6687 - val_loss: 0.6557 - val_acc: 0.6286\n",
      "Epoch 85/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6147 - acc: 0.6681 - val_loss: 0.6573 - val_acc: 0.6330\n",
      "Epoch 86/400\n",
      "6451/6451 [==============================] - 48s 7ms/sample - loss: 0.6187 - acc: 0.6673 - val_loss: 0.6511 - val_acc: 0.6268\n",
      "Epoch 87/400\n",
      "6451/6451 [==============================] - 55s 8ms/sample - loss: 0.6213 - acc: 0.6611 - val_loss: 0.6571 - val_acc: 0.6293\n",
      "Epoch 88/400\n",
      "1664/6451 [======>.......................] - ETA: 40s - loss: 0.6235 - acc: 0.6556"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4c65ff4c83f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X_train_std, y_train, epochs=400, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mytoken3_doc2Vec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0' '0' '1' '0' '1' '1' '0' '1' '1' '0' '0' '1' '1' '1' '1' '0' '1'\n",
      " '1' '0' '0' '1' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '1' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '1' '1' '0' '1' '1' '1' '0'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '1' '1' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '1' '0']\n",
      "['0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '1' '0' '1' '0' '0' '1' '0' '1'\n",
      " '1' '0' '0' '1' '0' '1' '0' '0' '0' '1' '1' '0' '1' '0' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '1' '0' '1' '1' '0' '0'\n",
      " '1' '1' '0' '0' '0' '1' '0' '0' '1' '0' '0' '1' '1' '0' '0' '1' '0' '0'\n",
      " '1' '0' '1' '0' '1' '1' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '1' '0' '0' '0' '0' '1' '0' '0' '1' '0']\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Good sanitize       0.75      0.77      0.76      1718\n",
      " Bad sanitize       0.69      0.66      0.67      1306\n",
      "\n",
      "     accuracy                           0.72      3024\n",
      "    macro avg       0.72      0.72      0.72      3024\n",
      " weighted avg       0.72      0.72      0.72      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test_std).astype('str')\n",
    "print(y_pred[:100])\n",
    "print(y_test[:100])\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, y_pred, \n",
    "                                    target_names=['Good sanitize', 'Bad sanitize']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training.\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Good sanitize       0.65      0.80      0.72      1718\n",
      " Bad sanitize       0.63      0.44      0.52      1306\n",
      "\n",
      "     accuracy                           0.65      3024\n",
      "    macro avg       0.64      0.62      0.62      3024\n",
      " weighted avg       0.64      0.65      0.63      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel='linear', C=1.0, gamma='auto', probability=True, random_state=None).fit(X_train_std, y_train)  # 线性核\n",
    "# rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=1.0).fit(X_train, y_train)  # 径向基核\n",
    "# poly_svc = svm.SVC(kernel='poly', degree=3, C=1.0, gamma='auto').fit(X_train, y_train)  # 多项式核\n",
    "print('Finished training.\\n');\n",
    "\n",
    "from sklearn import metrics\n",
    "predict_target = svc.predict(X_test_std)\n",
    "print(metrics.classification_report(y_test, predict_target, \n",
    "                                    target_names=['Good sanitize', 'Bad sanitize']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
