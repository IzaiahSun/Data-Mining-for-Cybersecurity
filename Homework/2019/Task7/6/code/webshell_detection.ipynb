{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import math\n",
    "import subprocess\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_webshell = os.listdir(\"./data/webshell/\")\n",
    "files_common = os.listdir(\"./data/normal/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal file: 412\n",
      "webshell file: 1634\n",
      "['305.php', '306.php', '400.php', '401.php']\n"
     ]
    }
   ],
   "source": [
    "print(\"normal file:\",len(files_common))\n",
    "print(\"webshell file:\",len(files_webshell))\n",
    "print(files_common[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打上文件的label标签，如果是webshell文件，则置label=1 否则 label=0\n",
    "labels_webshell = []\n",
    "labels_common = []\n",
    "for i in range(0,len(files_webshell)):\n",
    "    labels_webshell.append(1)\n",
    "for i in range(0,len(files_common)):\n",
    "    labels_common.append(0)\n",
    "\n",
    "\n",
    "for i in range(0,len(files_webshell)):\n",
    "    files_webshell[i] = \"D:/week11-webshell-detect/data/webshell/\" + files_webshell[i]\n",
    "for i in range(0,len(files_common)):\n",
    "    files_common[i] = \"D:/week11-webshell-detect/data/normal/\" + files_common[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2046, 2)\n",
      "                                                file  label\n",
      "0  D:/week11-webshell-detect/data/webshell/003928...      1\n",
      "1  D:/week11-webshell-detect/data/webshell/006620...      1\n",
      "2  D:/week11-webshell-detect/data/webshell/009752...      1\n",
      "3  D:/week11-webshell-detect/data/webshell/00d0f1...      1\n",
      "4  D:/week11-webshell-detect/data/webshell/0105d0...      1\n"
     ]
    }
   ],
   "source": [
    "files = files_webshell + files_common#将webshell和normal file进行合并\n",
    "labels = labels_webshell + labels_common\n",
    "\n",
    "datadict = {'file':files,'label':labels}\n",
    "df = pd.DataFrame(datadict,columns=['file','label'])\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取php中的opcode。\n",
    "def getopcode(x):\n",
    "    try:\n",
    "        cmd = \"php -dvld.active=1 -dvld.execute=0 \" + str(x)\n",
    "        output =  subprocess.getoutput(cmd)\n",
    "        oplist = re.findall(r'\\s(\\b[A-Z_]+\\b)\\s',output)\n",
    "        #print(oplist)\n",
    "        #print(str(x))\n",
    "        return oplist\n",
    "    except:\n",
    "        #print(\"error\" + str(x))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求文件的信息熵\n",
    "def getfileshan(x):\n",
    "    #length = 0\n",
    "    word = {}\n",
    "    p = 0\n",
    "    sum = 0\n",
    "    with open(x,'r',encoding='ISO-8859-1') as f:\n",
    "        content = f.readlines()\n",
    "        for i in content:\n",
    "            for j in i:\n",
    "                if j != '\\n' and j != ' ':\n",
    "                    if j not in word.keys():\n",
    "                        word[j] = 1\n",
    "                    else:\n",
    "                        word[j] = word[j] + 1\n",
    "                else:\n",
    "                    pass\n",
    "        f.close()\n",
    "    for i in word.keys():\n",
    "        sum = sum + word[i]\n",
    "    for i in word.keys():\n",
    "        p = p - float(word[i])/sum * math.log(float(word[i])/sum,2)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取词向量\n",
    "def getw2v(opc_list,label_list):\n",
    "    #print(label_list[0:10])\n",
    "    stop = []\n",
    "    w2v_list = []\n",
    "    for i in range(0,7789):\n",
    "        try:\n",
    "            #print(label_list[0:10])\n",
    "            tmp = []\n",
    "            name = opc_list[i]\n",
    "            #print(name[0])\n",
    "            for j in range(0,len(name)):\n",
    "                tmp.append(name[j])\n",
    "            w2v_list.append(tmp)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    model = Word2Vec(w2v_list, min_count = 1)\n",
    "    #print (model._vocabulary)\n",
    "    model.wv.save_word2vec_format('word2vec.txt',binary=False) \n",
    "    #return 0\n",
    "    #print model['a']\n",
    "    label_vect = []\n",
    "    wv_vect = []\n",
    "    for i in range(0,7789):\n",
    "        try:\n",
    "            #print(i)\n",
    "            name = opc_list[i]\n",
    "            tmp = []\n",
    "            vect = []\n",
    "            for j in range(0,len(name)):\n",
    "                if name[j] in stop:\n",
    "                    continue\n",
    "                tmp.append(model[name[j]])\n",
    "                if j >= 99:\n",
    "                    break\n",
    "            if len(tmp) < 100:\n",
    "                for k in range(0,100-len(tmp)):\n",
    "                    tmp.append([0]*100)\n",
    "            vect = np.vstack((x for x in tmp))\n",
    "            wv_vect.append(vect)\n",
    "            label_vect.append(label_list[i])\n",
    "            #if i ==100000:\n",
    "            #   break\n",
    "        except:\n",
    "            pass\n",
    "    wv_vect = np.array(wv_vect)\n",
    "    label_vect = np.array(label_vect)\n",
    "    return wv_vect,label_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                file  label  \\\n",
      "0  D:/week11-webshell-detect/data/webshell/003928...      1   \n",
      "1  D:/week11-webshell-detect/data/webshell/006620...      1   \n",
      "2  D:/week11-webshell-detect/data/webshell/009752...      1   \n",
      "3  D:/week11-webshell-detect/data/webshell/00d0f1...      1   \n",
      "4  D:/week11-webshell-detect/data/webshell/0105d0...      1   \n",
      "\n",
      "                                              opcode  \n",
      "0                                                 []  \n",
      "1  [E, O, E, INIT_FCALL, INIT_FCALL, SEND_VAL, SE...  \n",
      "2  [E, O, E, ASSIGN, ASSIGN, ASSIGN, ASSIGN, ASSI...  \n",
      "3  [E, O, E, INIT_FCALL, FETCH_R, FETCH_DIM_R, SE...  \n",
      "4  [E, O, E, ASSIGN, INIT_FCALL, FETCH_DIM_R, FET...  \n"
     ]
    }
   ],
   "source": [
    "df['opcode'] = df['file'].map(lambda x:getopcode(x))\n",
    "df = df.dropna()\n",
    "#print(getopcode())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2029, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  [-0.06511515  1.30076301  1.71048164 ... -0.39202583  0.16971405\n",
      "   -0.43985051]\n",
      "  [ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  [-0.06511515  1.30076301  1.71048164 ... -0.39202583  0.16971405\n",
      "   -0.43985051]\n",
      "  [ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  [-0.06511515  1.30076301  1.71048164 ... -0.39202583  0.16971405\n",
      "   -0.43985051]\n",
      "  [ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  [-0.06511515  1.30076301  1.71048164 ... -0.39202583  0.16971405\n",
      "   -0.43985051]\n",
      "  [ 1.20605826 -0.70300782  1.28268433 ...  1.6583811  -0.76650095\n",
      "    0.67054927]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]]\n",
      "[1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "print(df.shape)\n",
    "w2v_word_list,label_list = getw2v(df['opcode'],df['label'])\n",
    "print(w2v_word_list[1:5])\n",
    "print(label_list[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train = np.concatenate((w2v_word_list[0:500],w2v_word_list[1500:2000]))\n",
    "y_train = np.concatenate((label_list[0:500] , label_list[1500:2000]))\n",
    "x_test = np.concatenate((w2v_word_list[500:1500] , w2v_word_list[2000:]))\n",
    "y_test = np.concatenate((label_list[500:1500] , label_list[2000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding\n",
    "from keras.layers import LSTM\n",
    "import pickle\n",
    "model = Sequential()\n",
    "#model.add(Embedding())\n",
    "model.add(LSTM(128,dropout = 0.2,recurrent_dropout = 0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "\n",
    "pickle_file = open('webshell.model','wb')\n",
    "pickle.dump(model,pickle_file)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training....\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/16\n",
      "1000/1000 [==============================] - 6s 6ms/step - loss: 0.5580 - acc: 0.7560\n",
      "Epoch 2/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3594 - acc: 0.8730\n",
      "Epoch 3/16\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3076 - acc: 0.8910\n",
      "Epoch 4/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3190 - acc: 0.8930\n",
      "Epoch 5/16\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2659 - acc: 0.9140A: 0s - loss: 0.2642 - acc: 0.9\n",
      "Epoch 6/16\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2333 - acc: 0.9150\n",
      "Epoch 7/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1860 - acc: 0.9370\n",
      "Epoch 8/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1739 - acc: 0.9480\n",
      "Epoch 9/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2228 - acc: 0.9330\n",
      "Epoch 10/16\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1969 - acc: 0.9410A: 2s - loss: \n",
      "Epoch 11/16\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.1965 - acc: 0.9350\n",
      "Epoch 12/16\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2376 - acc: 0.9280\n",
      "Epoch 13/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2069 - acc: 0.9340\n",
      "Epoch 14/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3242 - acc: 0.8890\n",
      "Epoch 15/16\n",
      "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1764 - acc: 0.9490\n",
      "Epoch 16/16\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 0.2108 - acc: 0.9400\n",
      " evaling....\n",
      "1029/1029 [==============================] - 1s 1ms/step\n",
      "LSTM-score: 0.15109969656715355\n",
      "LSTM-accuracy: 0.9484936833034104\n"
     ]
    }
   ],
   "source": [
    "print ('start training....')\n",
    "model.fit(x_train,y_train,epochs = 16,batch_size = 32)\n",
    "print (' evaling....')\n",
    "score,acc = model.evaluate(x_test,y_test)\n",
    "print (\"LSTM-score:\",score)\n",
    "print(\"LSTM-accuracy:\",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
