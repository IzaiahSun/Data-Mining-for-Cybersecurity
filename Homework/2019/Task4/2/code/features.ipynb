{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel_letters = ['a', 'e', 'i', 'o', 'u']\n",
    "consonant_letters = [ 'b', 'c', 'd', 'f', 'g', 'h', \n",
    "                      'j', 'k', 'l', 'm', 'n', 'p', \n",
    "                      'q', 'r', 's', 't', 'v', 'w', \n",
    "                      'x', 'y', 'z']\n",
    "    \n",
    "# 这部分是辅助函数：\n",
    "def num_letters(domain):\n",
    "    count = 0;\n",
    "    for letter in domain.lower():\n",
    "        if letter in vowel_letters or letter in consonant_letters:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def num_vowels(domain):\n",
    "    num = 0;\n",
    "    for letter in domain.lower():\n",
    "        if is_vowel(letter):\n",
    "            num += 1\n",
    "    return num\n",
    "\n",
    "\n",
    "def num_consonant(domain):\n",
    "    num = 0;\n",
    "    for letter in domain.lower():\n",
    "        if is_consonant(letter):\n",
    "            num += 1\n",
    "    return num\n",
    "\n",
    "\n",
    "def is_letter(char):\n",
    "    letter = char.lower()\n",
    "    return True if letter in vowel_letters or letter in consonant_letters else False\n",
    "\n",
    "\n",
    "def is_num(char):\n",
    "    if char >= '0' and char <= '9':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_vowel(char):\n",
    "    letter = char.lower()\n",
    "    if letter in vowel_letters:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_consonant(char):\n",
    "    letter = char.lower()\n",
    "    if letter in consonant_letters:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_constant_consonant_list(domain):\n",
    "    cons_list = []\n",
    "    conso = re.finditer(r'([bcdfghjklmnpqrstvwxyz])*', domain.lower())\n",
    "    for node in conso:\n",
    "        if len(node.group()) > 1:\n",
    "            cons_list.append(node.group())\n",
    "    return cons_list\n",
    "\n",
    "\n",
    "def get_n_gram_dict(domain, n=2):\n",
    "    dict_ngram = {}\n",
    "    for i in range(len(domain)-n+1):\n",
    "        gram = \"\".join(domain[i:i+n])\n",
    "        if gram not in dict_ngram:\n",
    "            dict_ngram[gram] = 0\n",
    "        dict_ngram[gram] += 1;\n",
    "    return dict_ngram\n",
    "\n",
    "\n",
    "def get_freq_dict(domain):\n",
    "    freq_dict = dict(Counter(domain))\n",
    "    return freq_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这部分是特征抽取函数:\n",
    "\n",
    "# 1.domain长度\n",
    "def length_of(domain):\n",
    "    return len(str(domain))\n",
    "\n",
    "\n",
    "# 2.元音字母占全部字符的比例 - 元音特征\n",
    "def vowel_letter_ratio(domain):\n",
    "    return (float) (num_vowels(domain) / length_of(domain))\n",
    "\n",
    "\n",
    "# 3.连续的辅音(串数量)占全部字符的比例 - 辅音特征\n",
    "def constant_consonant_ratio(domain):\n",
    "    return (float) (len(get_constant_consonant_list(domain)) / length_of(domain))\n",
    "\n",
    "\n",
    "# 4.数字占全部字符比例 - 数字特征\n",
    "def number_ratio(domain):\n",
    "    count = 0\n",
    "    for letter in domain:\n",
    "        if is_num(letter):\n",
    "            count += 1\n",
    "    return (float) (count / length_of(domain))\n",
    "\n",
    "\n",
    "# 5.Domain信息熵\n",
    "def calc_entropy(domain):\n",
    "    ent = 0\n",
    "    l = length_of(domain)\n",
    "    all_letters = dict(Counter(domain)).keys()\n",
    "    freq_dict = get_freq_dict(domain)\n",
    "    for letter in all_letters:\n",
    "        frequency = freq_dict[letter]\n",
    "        ent -= (frequency/l) * np.log2(frequency/l)\n",
    "    return ent\n",
    "\n",
    "# 6.Domain中0-9、a-f总长度的比例\n",
    "def count_hex_digit_words_ratio(domain):\n",
    "    hex_count = 0\n",
    "    for letter in domain.lower():\n",
    "        if (letter >= 'a' and letter <= 'f') or is_num(letter):  #是hex digit\n",
    "                hex_count += 1\n",
    "    return (float) (hex_count / len(domain))\n",
    "\n",
    "# 7.唯一出现的字母占所有出现过的字母的比例\n",
    "def count_unique_letter_ratio(domain):\n",
    "    domain = domain.lower()\n",
    "    unq_count = 0\n",
    "    freq_dict = get_freq_dict(domain)\n",
    "    for value in freq_dict.values():\n",
    "        if value == 1:\n",
    "            unq_count += 1\n",
    "    return (float) (unq_count / len(freq_dict))\n",
    "        \n",
    "# 8.TLD顶级域检测\n",
    "def tld_is_com_or_cn(url):\n",
    "    slices = url.lower().split('.')\n",
    "    if slices[-1] == 'com' or slices[-1] == 'cn':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "    \n",
    "# 纯N-gram(2-gram)，要传X_train_std列表进来\n",
    "def psb_n_gram(domain_list, n=2):\n",
    "    domain_list = np.array(domain_list)\n",
    "    CV = CountVectorizer(ngram_range=(n,n), stop_words=None, decode_error='ignore', \n",
    "                        token_pattern=r'\\w', min_df=1)\n",
    "    return CV.fit_transform(domain_list).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n",
      "0.5\n",
      "1\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 1 0 0 0 1 0 0 1 1 0]\n",
      " [1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1\n",
      "  1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 1 0 0 0]\n",
      " [1 1 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 0 1 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 测试部分\n",
    "domain = 'abcbBcz'\n",
    "url = domain + '.com.cn'\n",
    "print(count_hex_digit_words_ratio(domain))\n",
    "print(count_unique_letter_ratio(domain))\n",
    "print(tld_is_com_or_cn(url))\n",
    "domain_list = ['google', '80ff81a92301bf7ed276', 'baidu', 'gmail', 'hao123', 'p52c101bf709baf2dd74']\n",
    "print(psb_n_gram(domain_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
