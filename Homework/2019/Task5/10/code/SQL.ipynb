{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(line,label):\n",
    "    num_len=0\n",
    "    capital_len=0\n",
    "    key_num=0\n",
    "    feature3=0\n",
    "    num_len=len(re.compile(r'\\d').findall(line))\n",
    "    if len(line)!=0:\n",
    "        num_f=num_len/len(line)#数字字符频率\n",
    "    else:\n",
    "        num_f=0\n",
    "    capital_len=len(re.compile(r'[A-Z]').findall(line))\n",
    "    if len(line)!=0:\n",
    "        capital_f=capital_len/len(line)#大写字母频率\n",
    "    else:\n",
    "        capital_f=0\n",
    "    line=line.lower()\n",
    "\n",
    "    key_num=line.count('and')+line.count('or')+line.count('xor')+line.count('sysobjects')+line.count('version')+line.count('substr')+line.count('len')+line.count('substring')+line.count('exists')\n",
    "    key_num=key_num+line.count('union')+line.count('asc')+line.count('inner join')+line.count('xp_cmdshell')+line.count('version')+line.count('exec')+line.count('having')+line.count('unnion')+line.count('order')+line.count('information schema')\n",
    "    key_num=key_num+line.count('load_file')+line.count('load data infile')+line.count('into outfile')+line.count('into dumpfile')\n",
    "    if len(line)!=0:\n",
    "        space_f=(line.count(\" \")+line.count(\"%20\"))/len(line)#空格百分比\n",
    "        special_f=(line.count(\"{\")*2+line.count('28%')*2+line.count('NULL')+line.count('[')+line.count('=')+line.count('?'))/len(line)\n",
    "        prefix_f=(line.count('\\\\x')+line.count('&')+line.count('\\\\u')+line.count('%'))/len(line)\n",
    "    else:\n",
    "        space_f=0\n",
    "        special_f=0\n",
    "        prefix_f=0\n",
    "    #print('%f,%f,%f,%f,%f,%f,%f,%f' % (len(line),key_num,capital_f,num_f,space_f,special_f,prefix_f,label))\n",
    "\n",
    "    return len(line),key_num,capital_f,num_f,space_f,special_f,prefix_f,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(odir,wdir,label):\n",
    "    f_input=open(wdir, 'w')\n",
    "    with open(odir, 'rb') as f:\n",
    "        data = [x.decode('utf-8').strip() for x in f.readlines()]\n",
    "        #print(data)\n",
    "        for line in data:\n",
    "            f_input.write('%f,%f,%f,%f,%f,%f,%f,%f' % (get_feature(line,label))+'\\n')\n",
    "\n",
    "    f_input.close()\n",
    "    return wdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_matrix=generate(\"./data/sqlnew.csv\",\"./data/sql_matrix.csv\",1)\n",
    "nor_matrix=generate(\"./data/normal_less.csv\",\"./data/nor_matrix.csv\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(sql_matrix)\n",
    "df.to_csv(\"./data/all_matrix.csv\",encoding=\"utf_8_sig\",index=False)\n",
    "df = pd.read_csv( nor_matrix)\n",
    "df.to_csv(\"./data/all_matrix.csv\",encoding=\"utf_8_sig\",index=False, header=False, mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import sklearn.ensemble as ek\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_max = pd.read_csv('./data/all_matrix.csv')\n",
    "arr=feature_max.values\n",
    "np.random.shuffle(arr)#打乱顺序\n",
    "data = np.delete(arr, -1, axis=1) #删除最后一列\n",
    "#print(arr)\n",
    "target=arr[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10. ,  1. ,  0. ,  0.2,  0.2,  0.1,  0. ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机划分训练集和测试集\n",
    "train_data,test_data,train_target,test_target = train_test_split(data,target,test_size=0.3,random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 3452, 0.0: 3529})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练集中正负样本的数量\n",
    "Counter(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 1523, 0.0: 1470})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试集中正负样本的数量\n",
    "Counter(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_target)+len(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = { \"DecisionTree    \":tree.DecisionTreeClassifier(max_depth=10),\n",
    "         \"RandomForest     \":ek.RandomForestClassifier(n_estimators=10,max_depth=2),\n",
    "         \"Adaboost         \":ek.AdaBoostClassifier(n_estimators=50),\n",
    "         \"GradientBoosting \":ek.GradientBoostingClassifier(n_estimators=50),\n",
    "         \"GNB              \":GaussianNB(),\n",
    "         \"LogisticRegression\":LogisticRegression()   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "算法        \t score_test    \t score_train    \t 精确率  \t  召回率 \t 混淆矩阵\n",
      "DecisionTree     \t 0.9939 \t 0.9997 \t 0.9980 \t 0.9901 \t [[1467    3]\n",
      " [  15 1508]]  \n",
      "RandomForest      \t 0.9799 \t 0.9769 \t 0.9972 \t 0.9632 \t [[1466    4]\n",
      " [  56 1467]]  \n",
      "Adaboost          \t 0.9956 \t 0.9979 \t 0.9986 \t 0.9927 \t [[1468    2]\n",
      " [  11 1512]]  \n",
      "GradientBoosting  \t 0.9939 \t 0.9975 \t 0.9966 \t 0.9914 \t [[1465    5]\n",
      " [  13 1510]]  \n",
      "GNB               \t 0.9766 \t 0.9785 \t 0.9795 \t 0.9743 \t [[1439   31]\n",
      " [  39 1484]]  \n",
      "LogisticRegression \t 0.9201 \t 0.9067 \t 0.9234 \t 0.9192 \t [[1354  116]\n",
      " [ 123 1400]]  \n"
     ]
    }
   ],
   "source": [
    "#测试不同算法的准确度\n",
    "print(\"算法        \\t score_test    \\t score_train    \\t 精确率  \\t  召回率 \\t 混淆矩阵\")\n",
    "#print(\"算法        \\t score_test    \\t score_train    \\t 精确率  \\t  召回率 \")\n",
    "for algo in model:\n",
    "    clf = model[algo]\n",
    "    clf.fit(train_data,train_target)\n",
    "    score_test = clf.score(test_data,test_target)\n",
    "    score_train = clf.score(train_data,train_target)\n",
    "   \n",
    "    y_pred=clf.predict(test_data)#预测\n",
    "    precision=metrics.precision_score(y_true=test_target,y_pred=y_pred)\n",
    "    recall=metrics.recall_score(y_true=test_target,y_pred=y_pred)\n",
    "    confusion=metrics.confusion_matrix(y_true=test_target,y_pred=y_pred)\n",
    "    joblib.dump(clf, './data/'+algo+'.model')\n",
    "    print((\"%s \\t %.6s \\t %.6s \\t %.6s \\t %.6s \\t %s  \")%(algo,score_test,score_train,precision,recall,confusion))\n",
    "    #print((\"%s \\t %.6s \\t %.6s \\t %.6s \\t %.6s \\t  \")%(algo,score_test,score_train,precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "算法           \t  预测结果\n",
      "DecisionTree     \t [1.] \n",
      "RandomForest      \t [1.] \n",
      "Adaboost          \t [1.] \n",
      "GradientBoosting  \t [1.] \n",
      "GNB               \t [1.] \n",
      "LogisticRegression \t [1.] \n"
     ]
    }
   ],
   "source": [
    "print(\"算法           \\t  预测结果\")\n",
    "for algo in model:\n",
    "    clf =joblib.load('./data/'+algo+'.model') \n",
    "    feature = get_feature(\"select *\",0)\n",
    "    feature = [feature[:7]]\n",
    "    y_pred=clf.predict(feature)#预测\n",
    "    print((\"%s \\t %.6s \")%(algo,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
