{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from urllib.parse import unquote\n",
    "# 缩小向量空间\n",
    "def GeneSeg(payload):\n",
    "    # lowercase\n",
    "    payload=payload.lower()\n",
    "    payload=unquote(payload)\n",
    "    payload,num=re.subn(r'\\d+',\"0\",payload)\n",
    "    payload,num=re.subn(r'(http|https)://[a-zA-Z0-9\\.@&/#!#\\?]+',\"http://u\", payload)\n",
    "    payload,num=re.subn(r'\\/\\*.?\\*\\/',\"\",payload)\n",
    "    r = '''\n",
    "        (?x)[\\w\\.]+?\\(\n",
    "        |\\)\n",
    "        |\"\\w+?\"\n",
    "        |'\\w+?'\n",
    "        |http://\\w\n",
    "        |</\\w+>\n",
    "        |<\\w+>\n",
    "        |<\\w+\n",
    "        |\\w+=\n",
    "        |>\n",
    "       |[\\w\\.]+\n",
    "    '''\n",
    "    return nltk.regexp_tokenize(payload,r)\n",
    "\n",
    "import csv\n",
    "csv_reader = csv.reader(open(\"./dmzo_nomal.csv\",'r'))\n",
    "content = []\n",
    "target=[]\n",
    "for line in csv_reader:\n",
    "    target.append(1)\n",
    "    content.append(line)\n",
    "csv_reader = csv.reader(open(\"./xssed.csv\",'r'))\n",
    "for line in csv_reader:\n",
    "    target.append(0)\n",
    "    content.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_word = []\n",
    "for i in content:\n",
    "    a = GeneSeg(i[0])\n",
    "    result_word.append(a)\n",
    "del(a,content,i,line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mode=', 'navigation', 'amp', 'categoryid=', '0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for i in result_word:\n",
    "    sentence = \"\"\n",
    "    for j in i:\n",
    "        sentence += j\n",
    "        sentence += \" \"\n",
    "    sentences.append(sentence)\n",
    "del(result_word)\n",
    "del(sentence,i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sid= amp ring= hentff0 amp id= amp list '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# 在30个单词后截断指令\n",
    "max_lens = 30\n",
    "# 只考虑最常用的10000\n",
    "word_max = 10000\n",
    "tokenizer = Tokenizer(num_words=word_max)\n",
    "tokenizer.x(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sid= amp ring= hentff0 amp id= amp list '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_samples = int(0.75*len(sentences))\n",
    "test_samples = len(sentences) - train_samples\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "word_index = tokenizer.word_index\n",
    "data = pad_sequences(sequences,maxlen=max_lens)\n",
    "labels = np.asarray(target)\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "X_train = data[:train_samples]\n",
    "y_train = labels[:train_samples]\n",
    "X_test = data[train_samples:]\n",
    "y_test = labels[train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1015 19:20:27.152863 4586128832 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1015 19:20:27.198287 4586128832 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1015 19:20:27.211700 4586128832 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1015 19:20:27.427363 4586128832 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1015 19:20:27.441509 4586128832 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1015 19:20:27.446759 4586128832 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 8)             80000     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                5248      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 85,281\n",
      "Trainable params: 85,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 19:20:28.138639 4586128832 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38899 samples, validate on 9725 samples\n",
      "Epoch 1/10\n",
      "38899/38899 [==============================] - 27s 691us/step - loss: 0.0866 - acc: 0.9745 - val_loss: 0.0463 - val_acc: 0.9877\n",
      "Epoch 2/10\n",
      "38899/38899 [==============================] - 25s 636us/step - loss: 0.0378 - acc: 0.9899 - val_loss: 0.0415 - val_acc: 0.9891\n",
      "Epoch 3/10\n",
      "38899/38899 [==============================] - 24s 612us/step - loss: 0.0365 - acc: 0.9905 - val_loss: 0.0391 - val_acc: 0.9900\n",
      "Epoch 4/10\n",
      "38899/38899 [==============================] - 24s 617us/step - loss: 0.0361 - acc: 0.9904 - val_loss: 0.0406 - val_acc: 0.9902\n",
      "Epoch 5/10\n",
      "38899/38899 [==============================] - 25s 636us/step - loss: 0.0355 - acc: 0.9906 - val_loss: 0.0380 - val_acc: 0.9903\n",
      "Epoch 6/10\n",
      "38899/38899 [==============================] - 26s 662us/step - loss: 0.0345 - acc: 0.9909 - val_loss: 0.0378 - val_acc: 0.9903\n",
      "Epoch 7/10\n",
      "38899/38899 [==============================] - 24s 627us/step - loss: 0.0340 - acc: 0.9910 - val_loss: 0.0375 - val_acc: 0.9902\n",
      "Epoch 8/10\n",
      "38899/38899 [==============================] - 25s 654us/step - loss: 0.0328 - acc: 0.9913 - val_loss: 0.0386 - val_acc: 0.9899\n",
      "Epoch 9/10\n",
      "38899/38899 [==============================] - 24s 610us/step - loss: 0.0325 - acc: 0.9914 - val_loss: 0.0376 - val_acc: 0.9892\n",
      "Epoch 10/10\n",
      "38899/38899 [==============================] - 24s 629us/step - loss: 0.0317 - acc: 0.9915 - val_loss: 0.0383 - val_acc: 0.9890\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Dense\n",
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(word_max,8,input_length=max_lens))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "model.summary()\n",
    "history = model.fit(X_train,y_train,epochs=10,batch_size=32,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9838361404158183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.98      0.99      0.98      8337\n",
      "    survived       0.99      0.98      0.98      7872\n",
      "\n",
      "    accuracy                           0.98     16209\n",
      "   macro avg       0.98      0.98      0.98     16209\n",
      "weighted avg       0.98      0.98      0.98     16209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "rfc_predict=rfc.predict(X_test)\n",
    "print(rfc.score(X_test,y_test))\n",
    "\n",
    "print(classification_report(y_test, rfc_predict, target_names=[\"died\", \"survived\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
