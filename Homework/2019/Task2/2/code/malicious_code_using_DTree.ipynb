{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_length_of_url(url):\n",
    "    return len(str(url))\n",
    "\n",
    "def is_IP(url):\n",
    "    p = re.compile('^((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)$')\n",
    "    if p.match(url):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_token_list(url):\n",
    "    return re.split('\\W+', url)\n",
    "\n",
    "def count_token(token_list):\n",
    "    return len(token_list)\n",
    "\n",
    "def average_token_length(token_list):\n",
    "    sum = 0\n",
    "    for token in token_list:\n",
    "        sum += len(token)\n",
    "    return sum / len(token_list)\n",
    "\n",
    "def count_sensitive_words(tokens_list):\n",
    "    sen_words = ['confirm', 'account', 'banking', 'secure', 'ebayisapi', 'webscr', 'login', 'signin', 'exe']\n",
    "    count = 0\n",
    "    for word in sen_words:\n",
    "        if word in tokens_list:\n",
    "            count += 1;\n",
    "    return count\n",
    "\n",
    "def count_dots(url):\n",
    "    return str(url).count('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fit\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "data_urls = data['url']\n",
    "data_labels = data['label']\n",
    "\n",
    "labels = []\n",
    "for i in data_labels:\n",
    "    if i == \"good\":\n",
    "        labels.append(1)\n",
    "    elif i == \"bad\":\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        print(\"label error.\")\n",
    "\n",
    "features = []\n",
    "for url in data_urls:\n",
    "    token_list = get_token_list(url)\n",
    "    features.append([get_length_of_url(url), is_IP(url), \n",
    "                     count_token(token_list), average_token_length(token_list), \n",
    "                     count_sensitive_words(token_list), count_dots(url)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=2019)\n",
    "\n",
    "# 数据预处理\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "    \n",
    "# 使用决策树\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree.fit(X_train_std, y_train)\n",
    "print('Done fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.86    Recall = 0.99\n"
     ]
    }
   ],
   "source": [
    "# 计算准确率、召回率\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "y_pred = dtree.predict(X_test_std, y_test)\n",
    "ACC = precision_score(y_test, y_pred)\n",
    "REC = recall_score(y_test, y_pred) \n",
    "print('Accuracy = %.2f    Recall = %.2f' %(ACC, REC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad URL\n"
     ]
    }
   ],
   "source": [
    "# 单个测试\n",
    "# 注：由于数据集中good url里包含的'www.'比较少但是bad url里比较多\n",
    "# 所以可能会把一些正常URL识别错，例如'www.baidu.com'会识别成bad\n",
    "# 测试时尝试去掉'www.'\n",
    "\n",
    "test_URL = 'www.baidu.com'\n",
    "\n",
    "test_features = []\n",
    "test_token_list = get_token_list(test_URL)\n",
    "test_features.append([get_length_of_url(test_URL), \n",
    "                      is_IP(test_URL), \n",
    "                      count_token(test_token_list), \n",
    "                      average_token_length(test_token_list), \n",
    "                      count_sensitive_words(test_token_list), \n",
    "                      count_dots(test_URL)])\n",
    "prediction = dtree.predict(test_features)[0]\n",
    "\n",
    "print('Good URL') if prediction == 1 else print('Bad URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
