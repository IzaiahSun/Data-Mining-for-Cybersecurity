{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress as ip\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tldextract\n",
    "\n",
    "# Method to count number of dots\n",
    "def countdots(url):  \n",
    "    return url.count('.')\n",
    "\n",
    "# Method to count number of delimeters\n",
    "def countdelim(url):\n",
    "    count = 0\n",
    "    delim=[';','_','?','=','&']\n",
    "    for each in url:\n",
    "        if each in delim:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "# Is IP addr present as th hostname, let's validate\n",
    "\n",
    "import ipaddress as ip #works only in python 3\n",
    "\n",
    "def is_ip(url):\n",
    "    try:\n",
    "        if ip.ip_address(url):\n",
    "            return 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def isPresentDSlash(url):\n",
    "    return url.count('//')\n",
    "\n",
    "def countSubDir(url):\n",
    "    return url.count('/')\n",
    "\n",
    "def countSubDomain(subdomain):\n",
    "    if not subdomain:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(subdomain.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done fit\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df_urls = df['url']\n",
    "df_labels = df['label']\n",
    "\n",
    "labels = []\n",
    "for i in df_labels:\n",
    "    if i == \"good\":\n",
    "        labels.append(1)\n",
    "    elif i == \"bad\":\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        printf(\"label error\")\n",
    "features = []\n",
    "for url in df_urls:\n",
    "    ext = tldextract.extract(url)\n",
    "    features.append([countdots(url),len(url),countdelim(url),is_ip(url),isPresentDSlash(url), countSubDir(url), countSubDomain(ext.subdomain)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=0, stratify=labels)\n",
    "\n",
    "# 数据预处理\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "    \n",
    "#使用决策树算法\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_std, y_train)\n",
    "print('Done fit')\n",
    "\n",
    "\n",
    "#使用支持向量机算法,耗时会特别长。。。。\n",
    "#clf = svm.SVC()\n",
    "#clf.fit(X_train, y_train)\n",
    "#print('Done fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.87  Accuracy = 0.86  Recall = 0.97\n"
     ]
    }
   ],
   "source": [
    "#分别计算准确率与召回率\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "y_pred = dt.predict(X_test_std, y_test)\n",
    "PRE = precision_score(y_test, y_pred)\n",
    "ACC = accuracy_score(y_test, y_pred)\n",
    "REC = recall_score(y_test, y_pred) \n",
    "print('Precision = %.2f  Accuracy = %.2f  Recall = %.2f' %(PRE, ACC, REC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.1cbc.com.cn :bad url\n"
     ]
    }
   ],
   "source": [
    "# 输入单个恶意url判断其安全性\n",
    "\n",
    "url = 'http://www.1cbc.com.cn'  #山寨工商银行\n",
    "ext = tldextract.extract(url)\n",
    "test_features = []\n",
    "test_features.append([countdots(url),len(url),countdelim(url),is_ip(url),isPresentDSlash(url), countSubDir(url), countSubDomain(ext.subdomain)])\n",
    "prediction = dt.predict(test_features)[0]\n",
    "\n",
    "if prediction == 1:\n",
    "    print(url + ' :bad url')\n",
    "else:\n",
    "    print(url + ' :good url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://edu.sc.gov.cn/ :good url\n"
     ]
    }
   ],
   "source": [
    "# 输入单个正常url判断其安全性\n",
    "\n",
    "url = 'http://edu.sc.gov.cn/'  #四川省教育厅\n",
    "ext = tldextract.extract(url)\n",
    "test_features = []\n",
    "test_features.append([countdots(url),len(url),countdelim(url),is_ip(url),isPresentDSlash(url), countSubDir(url), countSubDomain(ext.subdomain)])\n",
    "prediction = dt.predict(test_features)[0]\n",
    "\n",
    "if prediction == 1:\n",
    "    print(url + ' :good url')\n",
    "else:\n",
    "    print(url + ' :bad url')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
