# 机器学习——识别恶意URL

### 意义

网络攻击日益成为一个严重的问题，在这些攻击中，恶意URL经常扮演着重要角色，并被广泛应用到各种类型的攻击，比如钓鱼、垃圾邮件以及恶意软件中。检测恶意链接对于阻止这些攻击具有重要意义，多种技术目前已被应用于恶意URL的检测。由于传统的库识别方式非常耗时耗力，而且无法阻挡未知的恶意链接攻击，故近些年来基于机器学习的恶意URL识别方法得到越来越多的重视。



### 实现思路

1. 从网上下载到包含恶意URL和正常URL的数据集。 
2. 对无规律的数据集进行合理处理得到特征矩阵。 
3. 选择合适的机器学习算法，使用特征矩阵训练检测模型。 
4. 计算模型的准确率，精确率和召回率
5. 利用检测模型判断未知URL请求是恶意的还是正常的。



### 随机森林算法

#### 相关定义

随机森林指的是利用多棵树对样本进行训练并预测的一种分类器。该分类器最早由Leo Breiman和Adele Cutler提出，并被注册成了商标。

随机森林是一种多功能的机器学习算法，能够执行回归和分类的任务。同时，它也是一种数据降维手段，用于处理缺失值、异常值以及其他数据探索中的重要步骤，并取得了不错的成效。另外，它还担任了集成学习中的重要方法，在将几个低效模型整合为一个高效模型时大显身手。

在随机森林中，我们将生成很多的决策树，并不像在CART模型里一样只生成唯一的树。当在基于某些属性对一个新的对象进行分类判别时，随机森林中的每一棵树都会给出自己的分类选择，并由此进行“投票”，森林整体的输出结果将会是票数最多的分类选项；而在回归问题中，随机森林的输出将会是所有决策树输出的平均值。

#### 算法特点

- 在当前所有算法中，具有极好的准确率与高效性；
- 能够快速有效地运行在大数据集上；
- 能够处理具有高维特征的输入样本，而且不需要降维；
- 能够评估各个特征在分类问题上的重要性；
- 在生成过程中，能够获取到内部生成误差的一种无偏估计；
- 对于缺省值问题也能够获得很好得结果。

#### 工作原理

在随机森林中，每一个决策树“种植”和“生长”的规则如下：

1. 假设我们设定训练集中的样本个数为N，然后通过有重置的重复多次抽样来获得这N个样本，这样的抽样结果将作为我们生成决策树的训练集；
2. 如果有M个输入变量，每个节点都将随机选择m(m<M)个特定的变量，然后运用这m个变量来确定最佳的分裂点。在决策树的生成过程中，m的值是保持不变的；
3. 每棵决策树都最大可能地进行生长而不进行剪枝；
4. 通过对所有的决策树进行加总来预测新的数据（在分类时采用多数投票，在回归时采用平均）。



### 其他算法

#### 决策树

决策树是通过一系列规则对数据进行分类的过程。它提供一种在什么条件下会得到什么值的类似规则的方法。决策树分为分类树和回归树两种，分类树对离散变量做决策树，回归树对连续变量做决策树。

直观看上去，决策树分类器就像判断模块和终止块组成的流程图，终止块表示分类结果（也就是树的叶子）。判断模块表示对一个特征取值的判断（该特征有几个值，判断模块就有几个分支）。

如果不考虑效率等，那么样本所有特征的判断级联起来终会将某一个样本分到一个类终止块上。实际上，样本所有特征中有一些特征在分类时起到决定性作用，决策树的构造过程就是找到这些具有决定性作用的特征，根据其决定性程度来构造一个倒立的树--决定性作用最大的那个特征作为根节点，然后递归找到各分支下子数据集中次大的决定性特征，直至子数据集中所有数据都属于同一类。所以，构造决策树的过程本质上就是根据数据特征将数据集分类的递归过程，只需在当前数据集上哪个特征在划分数据分类时起决定性作用。

经过决策树分类，得到决策树的正确率约在94.86%

#### k近邻算法

所谓K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例（也就是上面所说的K个邻居）， 这K个实例的多数属于某个类，就把该输入实例分类到这个类中。

经过K近邻算法，得到准确率为 92.06%

#### 逻辑斯蒂回归

逻辑斯蒂回归是一个分类模型而不回归模型。其进行分类的主要思想是：根据现有数据对分类边界线建立回归公式，以此进行分类。这里的“回归”一词源于最佳拟合，表示要找到最佳拟合参数。而最佳拟合参数就是在训练分类器时，通过最优化算法获得。

经过逻辑斯蒂回归，得到的准确率约在84.65%，准确率较低



### 重要Python模块

#### numpy

numpy系统是Python的一种开源的数值计算扩展。这种工具可用来存储和处理大型矩阵，比Python自身的嵌套列表（nested list structure)结构要高效的多（该结构也可以用来表示矩阵（matrix）。

#### pandas

pandas 是基于numpy 的一种工具，该工具是为了解决数据分析任务而创建的。Pandas 纳入了大量库和一些标准的数据模型，提供了高效地操作大型数据集所需的工具。pandas提供了大量能使我们快速便捷地处理数据的函数和方法。经过一段时间的使用后就会发现，它是使Python成为强大而高效的数据分析环境的重要因素之一。

#### urllib.parse

urllib.parse定义了url的标准接口，实现url的各种抽取，包括url的解析，合并，拆分，拼接，编码，解码等。

#### tldextract

tldextract是一个第三方模块，意思就是Top Level Domain extract，即顶级域名提取。其返回的结构包含三部分，分别是：subdomain，domain，suffix。

#### whois

正如许多在线的whois IP和域名的查询工具一样，whois库可以直接查询域名注册信息，可以知道一个网站背后的公司信息，当然这是需要联网的。

#### train_test_split

在机器学习中，我们通常将原始数据按照比例分割为“测试集”和“训练集”，通常使用sklearn.model_selection里的train_test_split模块用来分割数据。它提供了许多参数选择，如：所要划分的样本特征集、所要划分的样本结果、样本占比（如果是整数的话就是样本的数量）、随机数种子、数据集按比例分配等。



### 提取数据集特征

根据对特征量进行的分析和对比结果，选取出以下特征用于区分恶意URL与正常URL。

1. URL长度
2. 斜杠数目
3. 有无子域名
4. 有无路径
5. 有无请求
6. 点数目
7. 路径长度
8. 请求长度
9. 域名长度
10. 后缀长度



### 准确率，精确率和召回率

根据名称就可以得知，这三个率的值越接近于1，模型的构建就越成功。

#### 准确率(accuracy)

对于给定的测试数据集，分类器正确分类的样本数与总样本数之比。

#### 精确率(precision)

精确率是针对我们预测结果而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)，也就是P = TP/(YP+FP)。

#### 召回率(recall)

召回率是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)，也就是R = TP/(TP+FN)。



### 说明

经过多次测试，本代码的准确率稳定在90％~95%，精确率和召回率也高于90%，但由于数据集本身的特点，在输入URL自动判定其安全性时应注意格式，即“www.bilibili.com”应写成“www.bilibili.com/”，否则会影响对URL恶意性的判断。

