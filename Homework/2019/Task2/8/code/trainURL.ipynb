{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greglamex/anaconda3/envs/scikit-learn/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import csv\n",
    "import tldextract\n",
    "import urllib.parse\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    URL = 'http://' + url if re.match(r'^(?:http|ftp)s?://', url) is None else url\n",
    "    return URL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数点\n",
    "def count_dots(url):\n",
    "    return url.count('.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def url_length(url):\n",
    "    return len(str(url))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 是否存在顶级域名\n",
    "def has_subdomain(url):\n",
    "    return 1 if tldextract.extract(url)[0] is not None else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 求出domain的长度\n",
    "def domain_lentgh(url):\n",
    "    return len(tldextract.extract(url)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 求出域名后缀的长度\n",
    "def suffix_length(url):\n",
    "    return len(tldextract.extract(url)[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 是否存有路径\n",
    "def has_path(url):\n",
    "    return 1 if urllib.parse.urlparse(url)[2] is not None else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 是否查询context\n",
    "def has_query(url):\n",
    "    return 1 if urllib.parse.urlparse(url)[4] is not None else 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算路径长度\n",
    "def path_length(url):\n",
    "    return len(urllib.parse.urlparse(url)[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算查询内容长度\n",
    "def query_length(url):\n",
    "    return len(urllib.parse.urlparse(url)[4])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数/\n",
    "def count_SubDir(url):\n",
    "    return url.count('/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数@\n",
    "def count_At(url):\n",
    "    return url.count('@')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 放弃\n",
    "def has_IP(url):\n",
    "    compile_rule = re.compile(r'(?<![\\.\\d])(?:\\d{1,3}\\.){3}\\d{1,3}(?![\\.\\d])')\n",
    "    match_list = re.findall(compile_rule, url)\n",
    "    if match_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_features(temp, url):\n",
    "    temp.append(count_dots(url))\n",
    "    temp.append(url_length(url))\n",
    "    temp.append(has_subdomain(url))\n",
    "    temp.append(has_path(url))\n",
    "    temp.append(has_query(url))\n",
    "    temp.append(path_length(url))\n",
    "    temp.append(query_length(url))\n",
    "    temp.append(domain_lentgh(url))\n",
    "    temp.append(suffix_length(url))\n",
    "    temp.append(count_SubDir(url))\n",
    "    temp.append(has_IP(url))\n",
    "    temp.append(count_At(url))\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************start****************\n",
      "**************saveing***************\n",
      "Training score:0.948513\n",
      "Testing score:0.909252\n",
      "Training precision score:0.796647\n",
      "Training recall score:0.667721\n",
      "test result:  BAD\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    url = []\n",
    "    label = []\n",
    "    temp = []\n",
    "    data = []\n",
    "    LaBel = []\n",
    "\n",
    "    with open(r'data.csv', 'r', encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            url.append(clean_url(row['url']))\n",
    "            if row['label'] == 'good':\n",
    "                label.append(0)\n",
    "            elif row['label'] == 'bad':\n",
    "                label.append(1)\n",
    "        csvfile.close()\n",
    "    # print(label[:10])\n",
    "    # print(countdots(url[1]))\n",
    "    for i in range(0, len(url)):\n",
    "        temp = get_features(temp, url[i])\n",
    "        data.append(temp)\n",
    "        LaBel.append(label[i])\n",
    "        temp = []\n",
    "\n",
    "    data = np.array(data)\n",
    "    LaBel = np.array(LaBel)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, LaBel, test_size=0.3, random_state=0)\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    sc.fit(X_train)\n",
    "    # 对数据集进行处理\n",
    "    url_tree = tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2,\n",
    "                                           min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=10,\n",
    "                                           random_state=None, max_leaf_nodes=None,\n",
    "                                           min_impurity_decrease=0.0, min_impurity_split=None, presort=False)\n",
    "\n",
    "    print(\"***************start****************\")\n",
    "    url_tree_save = url_tree.fit(X_train, y_train)\n",
    "    print(\"**************saveing***************\")\n",
    "    # joblib.dump(url_tree_save, 'C:/Users/Birdman/Desktop/data/url_tree.model')\n",
    "    print(\"Training score:%f\" % (url_tree.score(X_train, y_train)))\n",
    "    print(\"Testing score:%f\" % (url_tree.score(X_test, y_test)))\n",
    "    ''' \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Training score:%f\" % (clf.score(X_train, y_train)))\n",
    "    print(\"Testing score:%f\" % (clf.score(X_test, y_test)))\n",
    "    '''\n",
    "\n",
    "    y_pred = url_tree.predict(X_test)\n",
    "    print(\"Training precision score:%f\" % (precision_score(y_test, y_pred)))\n",
    "    print(\"Training recall score:%f\" % (recall_score(y_test, y_pred)))\n",
    "    # test\n",
    "\n",
    "    url = \"www.baidu.com\"\n",
    "    test = []\n",
    "    test = np.array(get_features(test, url))\n",
    "    if url_tree.predict([test]) == 1:\n",
    "        print(\"test result:  GOOD\")\n",
    "    else:\n",
    "        print(\"test result:  BAD\")\n",
    "    '''if clf.predict([test]) == 1:\n",
    "        print(\"test result:  GOOD\")\n",
    "    else:\n",
    "        print(\"test result:  BAD\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
